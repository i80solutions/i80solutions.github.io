<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>i80Solutions</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <!-- <link href="./lib/img/favicon.png" rel="icon"> -->
  <link href="./lib/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Roboto:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha512-...your_integrity_hash..." crossorigin="anonymous" referrerpolicy="no-referrer" />


  <!-- Vendor CSS Files -->
  <link href="./lib/vendor/aos/aos.css" rel="stylesheet">
  <link href="./lib/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="./lib/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="./lib/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="./lib/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="./lib/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->


  <link href="./lib/css/style.css" rel="stylesheet">
  <link href="./css/style.css" rel="stylesheet">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1LNXXD8W59"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1LNXXD8W59');
</script>

</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="d-flex align-items-center">
    <div class="container d-flex align-items-center justify-content-between">

      <h1 class="logo"><a href="index.html">i80<span>Solutions</span>.</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt=""></a>-->

      <nav id="navbar" class="navbar">
        <ul>
          <!-- <li><a class="nav-link scrollto active" href="./login.php">Home</a></li> -->
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <li><a class="nav-link scrollto" href="#how">How It Works</a></li>
          <li><a class="nav-link scrollto" href="#papers">Research Papers </a></li>
          <li><a class="nav-link scrollto" href="#collaborate">Collaborate</a></li>
      
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->
  <main id="main">

  
    <!-- ======= About Section ======= -->
     <!-- With Drak Background color -->
    <section id="about" class="about section-intro"> 


  <div class="container">
    <h2 class="mb-4">The Road to i80</h2>
    <div class="section-title" data-aos="fade-up" data-aos-delay="100">
      <img src="./images/i80d.png" alt="i80 metaphor for AI" class="img-fluid" style="border-radius:5px; width: 100%; height: auto; max-height: 25vh; object-fit: cover;">
    </div>
    <h5 class="mb-2">The Spark</h5>
    <p>I love to cook. Not by the book, but with intuition, memory, and whatever ingredients are at hand. Over the years, I've built a rich personal archive: dishes invented on the fly, surprising flavor combinations, and moments of improvisation captured in photos, notes, and conversations.</p>

    <p>
      Then, in January 2023, I encountered ChatGPT. I was blown away by its ability to answer questions and generate ideas. I'd ask about cuisines, techniques, or flavor pairings, and the responses were impressive. But when I asked, <i>"What did I cook that night with salmon and miso?"</i>, the reply came through as: <i>"I don't have access to your personal cooking history."</i>  For all their brilliance, these large language models (LLMs) didn't know my stories. They couldn't access the unique experiences, preferences, and memories that make me who I am.
    </p>
    <h5 class="mt-4 mb-2">The Turning Point</h5>
    <p>That's when it hit me: What if I could build an AI that feels like an LLM but knows what I know? Not a generic model trained on the internet, but a personal system capturing my cooking stories, my thought processes, my unique way of seeing the world. I imagined an AI that could answer, <i>"What would I have cooked with those ingredients?"</i> or even <i>"How would I have approached that problem?"</i> - not based on generic data, but on my own lived experience.</p>

    <p>This led me to Retrieval Augmented Generation (RAG), a technology that combines the conversational fluency of LLMs with a structured knowledge base tailored to specific domains. I started building a personal knowledge base - not of recipes, but of my cooking stories, complete with ingredients, intentions, and moments of inspiration. This system wouldn't just recite facts; it would reflect my style, my creativity, my voice.</p>


    <p>  That's also where the name "i80" comes from - inspired by the interstate highway built for clarity, structure, and speed. Just like that road, this system is meant to navigate complexity with confidence. No guesswork. No detours. Just grounded, context-aware answers that get you where you need to go.</p>
    
    <p>My vision goes beyond cooking. It's about creating an AI that acts like an extension of myself - one that preserves my memories and thought patterns for future reflection, or for others to access my perspective. It's a step toward digital continuity, a way to keep my perspective alive. And this approach isn't just personal. 
      The same technology can empower organizations - like hotel guest services, HR help desks, new employee onboarding assistants and many others - where public LLMs fall short due to a lack of domain-specific, trustworthy knowledge.</p>
    
    <h5 class="mt-4 mb-2">The Challenge Ahead</h5>
    <p>Building an AI that knows you like you know yourself is no small task. It requires blending the expressive power of LLMs with the precision of curated data.  But that's the road I'm on: a path to an AI that doesn't just answer, but remembers, reflects, and resonates.</p>
    
    <p>

      I don't know how far I'll go, or exactly what the final destination might look like. But that's part of the journey. What started as a spark - an idea to build an AI that truly understands me - has become a deeply personal exploration of memory, language, and technology.
    </p>
    <p>
      <h5 class="mt-4 mb-2">A Living Journal</h5>
      This website will document my road to i80. Through this space, I'll share what I'm learning along the way - the breakthroughs and the dead ends, the tools and techniques, the insights that emerge when <i>intuition meets iteration</i>.
      Whether it leads to a fully functioning personal AI, a new kind of storytelling engine, or something I haven't imagined yet, I'm here to explore it - and you're welcome to follow along.

    </p>
    
    <p>
      -  Alex P. Wang<br>
      <small>October 28, 2024</small>
     </p>



      </div>
    </section><!-- End Section -->

    <section id="started" class="py-5 bg-light text-dark">
      <div class="container">
        <h2 >How I Got Started</h2>
    
        <p>
          <img src="./images/person1s.png" alt="How I Got Started " style="float: right; width: 350px; margin-left: 20px; margin-bottom: 10px; border-radius: 3px;">
          I jumped in after the idea struck me - despite not knowing much about large language models. 
          Back in graduate school, I studied expert systems, AI, and neural networks, but LLMs were a whole new world. 
          I knew I'd need Python, but at that point, I hadn't written a single line of it.
        </p>
    
        <p>
          Thankfully, there's an abundance of resources online - and even better, we now have LLMs to help along the way. 
          It didn't take long for me to set up my initial Python environment using VS Code. And just like that, I was on my way.
        </p>
    
        <p>
          At first, I tried downloading open-source LLMs and fine-tuning them with my own knowledge base. 
          That quickly turned into a dead end. Fine-tuning is resource-intensive, hard to iterate, and - most importantly -
          poorly suited for domain knowledge that changes frequently or needs precise control. 
          It simply wasn't the right tool for a task where accuracy, flexibility, and explainability matter.
          Eventually, I came across the concept of Retrieval-Augmented Generation (RAG), and everything started to make more sense.
        </p>
    
      </div>
    </section>
    


    <section id="how" class="py-5 bg-white text-dark">
      <div class="container">
        <h2 >How It Works</h2>
        <p>
          I think the best way to explain how a Retrieval-Augmented Generation (RAG) system works is with an analogy - how a human answers a question.
          
        </p>
        <p>
          Imagine you're answering a question from your friend. First, you think back through your <strong>memory</strong> to find anything relevant - that's <strong>retrieval</strong>. Then, based on what you remember, your <strong>brain</strong> put the answer together in your own words - that's <strong>generation</strong>.
        </p>
        <p>That's essentially what a RAG system does. It has a curated <strong>knowledge base</strong> (its memory). The <strong>retriever</strong> pulls in the most relevant information from the knowledge base, and the <strong>orchestrator</strong> - like your brain - decides how to respond:  either directly or by calling on an LLM to help craft a clear, conversational answer.
        </p>
   
        <ul>
          <li><strong>Curate a knowledge base (memory)</strong> - Use your private, domain-specific content - facts, stories, documentation - to build a structured foundation.</li>
          <li><strong>Retrieve relevant content (retrieval)</strong> - When a question is asked, the retriever searches the knowledge base for snippets that are semantically related and have high similarity scores.</li>
          <li><strong>Orchestrate a response (brain)</strong>:
            <ul>
              <li>If the similarity score is high and the answer is straightforward, it returns the response directly.</li>
              <li>If the similarity is lower or the question is more nuanced, it sends the retrieved content to the LLM - along with clear instructions to stay grounded in the facts and avoid hallucination.</li>
            </ul>
          </li>
        </ul>
        <p class="mt-4">
          The result is an AI that answers more like a well-informed person: thoughtful, relevant, and context-aware.
        </p>
      </div>

    </section>



    <section id="building_blocks" class="pt-5 pb-5 bg-light">
      <div class="container">
        <div>
          <h2>Key Building Blocks</h2>
          <p>
            It didn't take me long to piece together the basic building blocks and get things up and running. At the heart of what I built is a modular system - one that reflects how we, as humans, think and respond. I set up a curated <strong>knowledge base</strong> to serve as memory. 
            A <strong>retriever</strong> fetches the most relevant information based on your question. 
            An <strong>orchestrator</strong> - something I fine-tuned carefully - decides whether to respond directly or synthesize information from multiple sources with the help of an <strong>LLM</strong>.
          </p>
          <p>
            Once I had these core parts working together, things really started to click. The setup gave me a solid foundation to start experimenting - exactly the kind of system I had envisioned from the very beginning.
          </p>
        </div>
    
        <div class="row">
          <div class="col-md-6 mb-4">
            <div class="card border-0 shadow-sm h-100 text-center">
              <div class="card-body">
                <div class="icon mb-3" style="font-size: 2rem; color:rgb(22, 52, 85);">
                  <i class="fa-solid fa-brain"></i>
                </div>
                <h5 class="card-title">Knowledge Base</h5>
                <p class="mt-3">A structured memory system built from your content. Text is transformed into semantic vectors and stored in a vector database for fast, meaningful retrieval.</p>
              </div>
            </div>
          </div>
    
          <div class="col-md-6 mb-4">
            <div class="card border-0 shadow-sm h-100 text-center">
              <div class="card-body">
                <div class="icon mb-3" style="font-size: 2rem; color:rgb(22, 52, 85);">
                  <i class="fa-solid fa-arrow-up-right-from-square"></i>
                </div>
                <h5 class="card-title">Retriever</h5>
                <p class=" mt-3">Finds the most relevant entries from the knowledge base by comparing the question to stored vectors using similarity scores.</p>
              </div>
            </div>
          </div>

            
          <div class="col-md-6 mb-4">
            <div class="card border-0 shadow-sm h-100 text-center">
              <div class="card-body">
                <div class="icon mb-3" style="font-size: 2rem; color:rgb(22, 52, 85);">
                  <i class="fa-solid fa-microchip"></i>
                </div>
                <h5 class="card-title">Orchestrator</h5>
                <p class="mt-3">Decides how to respond - sometimes returning retrieved content directly, or invoking the LLM for synthesis when needed.</p>
              </div>
            </div>
          </div>
    
          <div class="col-md-6 mb-4">
            <div class="card border-0 shadow-sm h-100 text-center">
              <div class="card-body">
                <div class="icon mb-3" style="font-size: 2rem; color:rgb(22, 52, 85);">
                  <i class="fa-solid fa-language"></i>
                </div>
                <h5 class="card-title">LLM </h5>
                <p class=" mt-3">Produces answers in natural language,  using the retrieved content as context for thoughtful, accurate responses.</p>
              </div>
            </div>
          </div>
  
        </div>
      </div>
    </section>


      <section id="challenges" class="services ">
        <div class="container" data-aos="fade-up">
  
          <h2>Key Challenges</h2>

          <p>
            The concept sounded simple - until I actually started building and testing my initial knowledge base.
          
            One of the first things I had to understand was how the system makes sense of conversational language. It does this through a technique called <em>embeddings</em>. In simple terms, embeddings convert text into numbers (technically, vectors) - representations that capture meaning, not just literal words. This allows the system to compare concepts and retrieve content that's semantically relevant to the question being asked, even when the wording or language differs.
          </p>
          
          <p>
            With that foundation in place, a new challenge emerged: what content should I embed? At first, I followed the conventional method of breaking documents into evenly sized chunks. But in practice, this approach often missed the essence of what users were really asking. What turned out to be far more effective - especially in a focused domain - was creating <em>query-focused embeddings</em> that align more closely with the actual questions people tend to ask. That shift significantly improved the system's performance and reliability.
          
            It laid the foundation for my solution. Of course, embeddings are just one part of the puzzle - many other challenges still remain.
          </p>


  
          <div class="row">

            <div class="col-lg-4 col-md-6 d-flex align-items-stretch" data-aos="zoom-in" data-aos-delay="300">
              <div class="icon-box service-item  bg-light" style="border-radius: 5px";>
     
                <h5>Embedding Quality</h5>
                <p>Poor or inconsistent embedding quality due to vague text, evolving language, or model drift. Embedding mismatches lead to retrieval errors - especially over time</p>
              </div>
            </div>

            <div class="col-lg-4 col-md-6 d-flex align-items-stretch  mt-4 mt-lg-0 " data-aos="zoom-in" data-aos-delay="100">
              <div class="icon-box service-item  bg-light" style="border-radius: 5px";>

                <h5>Query Understanding</h5>
                <p>Interpreting vague or conversational questions - especially when context is implied or missing. Handling multi-turn conversations or follow-ups that reference previous questions or answers</p>
              </div>
            </div>
  



            <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0" data-aos="zoom-in" data-aos-delay="200">
              <div class="icon-box service-item bg-light" style="border-radius: 5px;">
   
                <h5>Retrieval Accuracy</h5>
                <p>Ensuring the right pieces of information are found, ranked by relevance, and passed correctly to the language model.</p>
              </div>
            </div>

    <p>
            <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0" data-aos="zoom-in" data-aos-delay="300">
              <div class="icon-box service-item  bg-light" style="border-radius: 5px";>
     
                <h5>Knowledge Base Coverage</h5>
                <p>Capturing enough structured, relevant knowledge to confidently answer the real-world questions users actually ask. Keeping the knowledge base up to date, pruning outdated info.</p>
              </div>
            </div>


            <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0" data-aos="zoom-in" data-aos-delay="300">
              <div class="icon-box service-item  bg-light" style="border-radius: 5px";>
     
                <h5>Multilingual Support</h5>
                <p>Accurately retrieving and generating across multiple languages. Embeddings and language models trained in one language often degrade in performance with others.</p>
              </div>
            </div>

            <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0" data-aos="zoom-in" data-aos-delay="300">
              <div class="icon-box service-item  bg-light" style="border-radius: 5px";>
     
                <h5>Hallucination Control</h5>
                <p>Making sure the model generates responses based only on trusted knowledge, avoiding plausible-sounding fabrications.</p>
              </div>
            </div>

  
  
          </div>
       
        </div>
      </section><!-- End challenges Section -->
      <p></p>
      <section id="papers" class="services  bg-light">
        <div class="container">
          <h2>Research Papers</h2>
          <p>
          Based on the challenges encountered while building the framework, I've identified several key areas for deeper exploration. I'm actively researching these topics and documenting my findings through a series of evolving papers - continuously updated as I discover new insights and make ongoing progress.
         </p>
          <ul>
            <li><a href="papers/p1.pdf" target="new" style="color: #091291;">1. Enhancing Query Retrieval Precision Through Optimized Embedding Text Selection</a></li>
            <li>2. Embedding Question Intent: A Precision-First Approach to Retrieval in Narrow Domains</li>
            <li>3. Embedding with Targeted Language: Enhancing Intent Matching in Multilingual RAG Systems</li>
            <li>4. Tracking Domain Coverage Growth in Narrow Knowledge Spaces</li>
            <li>5. Learning from Queries: Automating Intent Expansion in RAG Systems</li>
            <li>6. Precision Routing in Hybrid RAG: Balancing Retrieval, Generation, and Escalation</li>
            <li>7. Calibrating Confidence in RAG: Threshold Tuning for Trustworthy Retrieval and Routing</li>
            <li>8. Beyond Retrieval: Integrating RAG with APIs and Agent Actions in Private Domains</li>
          </ul>
       <!---  
       <p><a href="https://github.com/i80solutions/intelliaorag-research" class="btn btn-dark mt-2">View Research Repository</a></p>
       --> 
        </div>
      </section>











      <section id="collaborate" class="section-last">
        <div class="container">
          <h2 class="mb-4">Want to Collaborate?</h2>
          
  
        <div class="container">
  
          <p>This is an ongoing personal research journey - not a finished product, but a path of discovery. There are many challenges ahead: from capturing intent to handling ambiguity, from structuring knowledge to scaling across subjects within a domain. I'm approaching it step by step, using a divide-and-conquer mindset to explore, test, and refine. Is the end goal too ambitious? Perhaps. But I'm confident that I'll make progress, uncover interesting insights, and grow along the way.
             <br><br>If you're working on similar problems or have ideas to share, I welcome collaboration and conversation. Let's learn from each other.
          </p> <p>Want to collaborate or learn more?
              <br>
            Email me at <a href="mailto:alex@i80.com">alex@i80.com</a></p>
          </div>
      </section>

 
 


  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container py-4">
    <div class="copyright">
      &copy; 2025 Copyright <strong><span>i80Solutions</span></strong>. All Rights Reserved
  </div>
    </div>
  </footer><!-- End Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="./lib/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="./lib/vendor/aos/aos.js"></script>
  <script src="./lib/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="./lib/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="./lib/vendor/swiper/swiper-bundle.min.js"></script>
  <!-- <script src="./lib/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="./lib/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="./lib/vendor/waypoints/noframework.waypoints.js"></script> -->
  <script src="./lib/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="./lib/js/main.js"></script>

</body>

</html>